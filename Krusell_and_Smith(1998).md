# __Krusell and Smith - Income and Wealth Heterogeneity in the Macroeconomy - Journal of Political Economy - (1998)__

# Replication made by Alejandro Rojas-Bernal. Commentaries or suggestions to `alejandro.rojas@alumni.ubc.ca`

Alejandro-Rojas-Bernal.github.io/Aiyagari(1994).md

## __1. The model__

### __1.1 Producer Problem__

Production of the good is given by a Cobb-Douglas function of aggregate capital <img src="https://tex.s2cms.ru/svg/%5Cbar%7BK%7D" alt="\bar{K}" /> and labor force <img src="https://tex.s2cms.ru/svg/%5Cbar%7BL%7D" alt="\bar{L}" />

<img src="https://tex.s2cms.ru/svg/Y%20%3D%20z%20%5Cbar%7BK%7D%5E%5Calpha%20%5Cbar%7BL%7D%5E%7B1-%5Calpha%7D" alt="Y = z \bar{K}^\alpha \bar{L}^{1-\alpha}" />

and per capita output is given by per capital assets <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D" alt="\bar{k}" /> and per capita effective labor supply <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bl%7D" alt="\bar{l}" />

<img src="https://tex.s2cms.ru/svg/y%20%3D%20z%20%5Cbar%7Bk%7D%5E%5Calpha%20%5Cbar%7Bl%7D%5E%7B1-%5Calpha%7D" alt="y = z \bar{k}^\alpha \bar{l}^{1-\alpha}" />

where the competitive prices for inputs are given by

<img src="https://tex.s2cms.ru/svg/%20w%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%20%3D%20%5Cleft(1-%5Calpha%5Cright)z%5Cleft(%5Cfrac%7B%5Cbar%7Bk%7D%7D%7B%5Cbar%7Bl%7D%7D%5Cright)%5E%7B%5Calpha%7D" alt=" w\left(\bar{k}, \bar{l}, z\right) = \left(1-\alpha\right)z\left(\frac{\bar{k}}{\bar{l}}\right)^{\alpha}" />
<img src="https://tex.s2cms.ru/svg/%20r%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%20%3D%20%5Calpha%20z%5Cleft(%5Cfrac%7B%5Cbar%7Bk%7D%7D%7B%5Cbar%7Bl%7D%7D%5Cright)%5E%7B%5Calpha-1%7D" alt=" r\left(\bar{k}, \bar{l}, z\right) = \alpha z\left(\frac{\bar{k}}{\bar{l}}\right)^{\alpha-1}" />

In the paper <img src="https://tex.s2cms.ru/svg/%5Calpha%20%3D%200.36" alt="\alpha = 0.36" /> is used.

### __1.2 Consumer Problem__

The individual problem is to maximize

<img src="https://tex.s2cms.ru/svg/E_0%5Cleft%5C%7B%5Csum_%7Bt%3D0%7D%5E%7B%5Cinfty%7D%5Cbeta%5Et%20U(C_t)%5Cright%5C%7D" alt="E_0\left\{\sum_{t=0}^{\infty}\beta^t U(C_t)\right\}" />

with

<img src="https://tex.s2cms.ru/svg/U(c)%3D%5Cunderset%7Bv%20%5Crightarrow%20%5Csigma%7D%7BLim%7D%5Cfrac%7Bc%5E%7B1-v%7D-1%7D%7B1-v%7D" alt="U(c)=\underset{v \rightarrow \sigma}{Lim}\frac{c^{1-v}-1}{1-v}" />

or its equivalent Bellman equation

<img src="https://tex.s2cms.ru/svg/V%5Cleft(k%2C%5Cepsilon%5Clvert%20%5CGamma%2C%20z%5Cright)%20%3D%20%5Cunderset%7Bc%2Ck'%7D%7BMax%7D%5Cleft%5C%7BU(c)%2B%5Cbeta%20E%5Cleft%5BV%5Cleft(k'%2C%5Cepsilon'%7C%20%5CGamma'%2Cz'%5Cright)%5Cright%5D%5Cright%5C%7D" alt="V\left(k,\epsilon\lvert \Gamma, z\right) = \underset{c,k'}{Max}\left\{U(c)+\beta E\left[V\left(k',\epsilon'| \Gamma',z'\right)\right]\right\}" />

subject to

<img src="https://tex.s2cms.ru/svg/c%20%2B%20k'%20%3D%20r%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%20k%20%2B%20w%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%5Ctilde%7Bl%7D%5Cepsilon%20%2B%20%5Cleft(1-%5Cdelta%5Cright)%20k" alt="c + k' = r\left(\bar{k}, \bar{l}, z\right) k + w\left(\bar{k}, \bar{l}, z\right)\tilde{l}\epsilon + \left(1-\delta\right) k" />

<img src="https://tex.s2cms.ru/svg/%5CGamma'%20%3D%20H%5Cleft(%5CGamma%2C%20z%2C%20z'%5Cright)" alt="\Gamma' = H\left(\Gamma, z, z'\right)" />

<img src="https://tex.s2cms.ru/svg/%20k'%20%5Cge%200%20" alt=" k' \ge 0 " />

<img src="https://tex.s2cms.ru/svg/%20c%20%3E%200%20" alt=" c &gt; 0 " />

<img src="https://tex.s2cms.ru/svg/%5Ctilde%7Bl%7D%3D1" alt="\tilde{l}=1" />

where <img src="https://tex.s2cms.ru/svg/%5CGamma" alt="\Gamma" /> represents the current distribution of capital, <img src="https://tex.s2cms.ru/svg/z" alt="z" /> the aggregate productivity of the economy and <img src="https://tex.s2cms.ru/svg/H" alt="H" /> the transition matrix for the distribution <img src="https://tex.s2cms.ru/svg/%5CGamma" alt="\Gamma" /> to distribution <img src="https://tex.s2cms.ru/svg/%5CGamma'" alt="\Gamma'" /> when the aggregate productivity changes from <img src="https://tex.s2cms.ru/svg/z" alt="z" /> to <img src="https://tex.s2cms.ru/svg/z'" alt="z'" />. The household has a policy function decision rule to update his asset holdings <img src="https://tex.s2cms.ru/svg/f%3A%20k'%20%3D%20f%5Cleft(k%2C%5Cepsilon%5Clvert%20%5CGamma%2C%20z%5Cright)" alt="f: k' = f\left(k,\epsilon\lvert \Gamma, z\right)" />.

Agents are subject to two idiosyncratic productivity shocks, either they are employed and <img src="https://tex.s2cms.ru/svg/%5Cepsilon%20%3D1" alt="\epsilon =1" />, or they are unemployed an <img src="https://tex.s2cms.ru/svg/%5Cepsilon%3D0" alt="\epsilon=0" />.

To reflect a one quarter period the following parameters are imposed <img src="https://tex.s2cms.ru/svg/%5Cbeta%3D0.99" alt="\beta=0.99" /> and <img src="https://tex.s2cms.ru/svg/%5Cdelta%20%3D%200.025" alt="\delta = 0.025" />. The inverse elasticity of substitution is assumed with <img src="https://tex.s2cms.ru/svg/%5Csigma%3D1" alt="\sigma=1" />.

### __1.3 Aggregate Uncertainty__

The economy has two possible aggregate shocks <img src="https://tex.s2cms.ru/svg/z%3Dz_g" alt="z=z_g" />, <img src="https://tex.s2cms.ru/svg/z%3Dz_b" alt="z=z_b" /> that follow a first order Markov structure with transition probabilities <img src="https://tex.s2cms.ru/svg/%5Cpi_%7Bss'%7D" alt="\pi_{ss'}" />, i.e. the probability that the aggregate shock next period is <img src="https://tex.s2cms.ru/svg/z_%7Bs'%7D" alt="z_{s'}" /> given that <img src="https://tex.s2cms.ru/svg/z_s" alt="z_s" /> is observed this period.

Individual and aggregate shocks are correlated, and the individual shocks are assumed to satisify a law of large numbers.

The number of unemployed agents are always <img src="https://tex.s2cms.ru/svg/%5Cmu_g" alt="\mu_g" /> in good times and <img src="https://tex.s2cms.ru/svg/%5Cmu_b" alt="\mu_b" /> in bad times. <img src="https://tex.s2cms.ru/svg/%5Cpi_%7Bss'%2C%5Cepsilon%5Cepsilon'%7D" alt="\pi_{ss',\epsilon\epsilon'}" /> denotes the probability of transition from state <img src="https://tex.s2cms.ru/svg/%5Cleft(z_s%2C%5Cepsilon%5Cright)" alt="\left(z_s,\epsilon\right)" /> today to <img src="https://tex.s2cms.ru/svg/%5Cleft(z_%7Bs'%7D%2C%5Cepsilon'%5Cright)" alt="\left(z_{s'},\epsilon'\right)" /> tomorrow.

Transition probabilities satisfy the following sixteen restrictions

<img src="https://tex.s2cms.ru/svg/%5Cpi_%7Bss'%2C00%7D%2B%5Cpi_%7Bss'%2C01%7D%3D%5Cpi_%7Bss'%2C10%7D%2B%5Cpi_%7Bss'%2C11%7D%3D%5Cpi_%7Bss'%7D" alt="\pi_{ss',00}+\pi_{ss',01}=\pi_{ss',10}+\pi_{ss',11}=\pi_{ss'}" />

<img src="https://tex.s2cms.ru/svg/%5Cmu_s%20%5Cfrac%7B%5Cpi_%7Bss'%2C00%7D%7D%7B%5Cpi_%7Bss'%7D%7D%2B%5Cleft(1-%5Cmu_s%5Cright)%5Cfrac%7B%5Cpi_%7Bss'%2C10%7D%7D%7B%5Cpi_%7Bss'%7D%7D" alt="\mu_s \frac{\pi_{ss',00}}{\pi_{ss'}}+\left(1-\mu_s\right)\frac{\pi_{ss',10}}{\pi_{ss'}}" />

for all four possible values <img src="https://tex.s2cms.ru/svg/(s%2Cs')" alt="(s,s')" />, and the following two additional restrictions <img src="https://tex.s2cms.ru/svg/%5Cpi_%7Bgg%7D%2B%5Cpi_%7Bgb%7D%3D1" alt="\pi_{gg}+\pi_{gb}=1" /> and <img src="https://tex.s2cms.ru/svg/%5Cpi_%7Bbg%7D%2B%5Cpi_%7Bbb%7D%3D1" alt="\pi_{bg}+\pi_{bb}=1" />.

Values are set to <img src="https://tex.s2cms.ru/svg/%5Cmu_g%3D0.04" alt="\mu_g=0.04" />, <img src="https://tex.s2cms.ru/svg/%5Cmu_b%3D0.1" alt="\mu_b=0.1" />, <img src="https://tex.s2cms.ru/svg/z_g%3D1.01" alt="z_g=1.01" />, and <img src="https://tex.s2cms.ru/svg/z_b%3D0.99" alt="z_b=0.99" /> implying macroeconomic fluctions similar to the ones observed in the postwar U.S. series.

The process for <img src="https://tex.s2cms.ru/svg/%5Cleft(z%2C%5Cepsilon%5Cright)" alt="\left(z,\epsilon\right)" /> chosen so that the average duration of both good and bad times is eight quarters and the average duration of unemployment is <img src="https://tex.s2cms.ru/svg/1.5" alt="1.5" /> quarters in good times and <img src="https://tex.s2cms.ru/svg/2.5" alt="2.5" /> quarters in bad times. To close the system they impose <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%5Cpi_%7Bgb00%7D%7D%7B%5Cpi_%7Bgb%7D%7D%3D1.25%5Cfrac%7B%5Cpi_%7Bbb00%7D%7D%7B%5Cpi_%7Bbb%7D%7D" alt="\frac{\pi_{gb00}}{\pi_{gb}}=1.25\frac{\pi_{bb00}}{\pi_{bb}}" /> and <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%5Cpi_%7Bbg00%7D%7D%7B%5Cpi_%7Bbg%7D%7D%3D0.75%5Cfrac%7B%5Cpi_%7Bgg00%7D%7D%7B%5Cpi_%7Bgg%7D%7D" alt="\frac{\pi_{bg00}}{\pi_{bg}}=0.75\frac{\pi_{gg00}}{\pi_{gg}}" />.

### __1.4 Recursive Competitive Equilibrium__

A recursive competitive equilibrium is a law of motion <img src="https://tex.s2cms.ru/svg/H" alt="H" />, a pair of individual functions <img src="https://tex.s2cms.ru/svg/V" alt="V" /> and <img src="https://tex.s2cms.ru/svg/f" alt="f" />, and pricing functions <img src="https://tex.s2cms.ru/svg/%5Cleft(r%2Cw%5Cright)" alt="\left(r,w\right)" /> such that:

1. <img src="https://tex.s2cms.ru/svg/%5Cleft(V%2Cf%5Cright)" alt="\left(V,f\right)" /> solve the consumer's problem.
2. <img src="https://tex.s2cms.ru/svg/r" alt="r" /> and <img src="https://tex.s2cms.ru/svg/w" alt="w" /> are competitive.
3. <img src="https://tex.s2cms.ru/svg/H" alt="H" /> is generated by <img src="https://tex.s2cms.ru/svg/f" alt="f" />, i.e. aggregation of idiosyncrative optimal choices explains the dynamic of capital distribution.

### __1.5 Computational Strategy__

<img src="https://tex.s2cms.ru/svg/%5CGamma" alt="\Gamma" /> is a high dimensional object. For this reason we assume bounded rationality in the perception of the evolution of <img src="https://tex.s2cms.ru/svg/%5CGamma" alt="\Gamma" />.

Therefore we assume that the agents only look at the first <img src="https://tex.s2cms.ru/svg/I" alt="I" /> moments of <img src="https://tex.s2cms.ru/svg/%5CGamma" alt="\Gamma" /> denotes as <img src="https://tex.s2cms.ru/svg/m%3D%5Cleft(m_1%2Cm_2%2C%20%5Cdots%2Cm_I%5Cright)" alt="m=\left(m_1,m_2, \dots,m_I\right)" />. The law of motion for the <img src="https://tex.s2cms.ru/svg/I" alt="I" /> moments is given by a function <img src="https://tex.s2cms.ru/svg/H_I" alt="H_I" /> that belongs to a class <img src="https://tex.s2cms.ru/svg/%5Cmathscr%7BP%7D" alt="\mathscr{P}" />. This function <img src="https://tex.s2cms.ru/svg/H_I" alt="H_I" />:

1. Yields the best fit within the class <img src="https://tex.s2cms.ru/svg/%5Cmathscr%7BP%7D" alt="\mathscr{P}" /> to the simulated behaviour of <img src="https://tex.s2cms.ru/svg/m" alt="m" /> in the data. .
2. Yields a fit that is close to perfect in the sense that <img src="https://tex.s2cms.ru/svg/H_I" alt="H_I" /> tracks the behaviour of <img src="https://tex.s2cms.ru/svg/m" alt="m" /> in an almost exact way.

For solve this type of approximate equilibrium Krussel and Smith assume a <img src="https://tex.s2cms.ru/svg/H_1" alt="H_1" /> log-linear:

<img src="https://tex.s2cms.ru/svg/z%20%3D%20z_g%20%5C%3B%5C%3B%20log%20%5Cbar%7Bk%7D'%3D%20%5Calpha_0%20%2B%20%5Calpha_1%20%5Cbar%7Bk%7D%2C" alt="z = z_g \;\; log \bar{k}'= \alpha_0 + \alpha_1 \bar{k}," />

<img src="https://tex.s2cms.ru/svg/z%20%3D%20z_b%20%5C%3B%5C%3B%20log%20%5Cbar%7Bk%7D'%3D%20%5Cbeta_0%20%2B%20%5Cbeta_1%20%5Cbar%7Bk%7D." alt="z = z_b \;\; log \bar{k}'= \beta_0 + \beta_1 \bar{k}." />

This allows agents to solve:

<img src="https://tex.s2cms.ru/svg/V%5Cleft(k%2C%5Cepsilon%5Clvert%20%5Cbar%7Bk%7D%2C%20z%5Cright)%20%3D%20%5Cunderset%7Bc%2Ck'%7D%7BMax%7D%5Cleft%5C%7BU(c)%2B%5Cbeta%20E%5Cleft%5BV%5Cleft(k'%2C%5Cepsilon'%7C%20%5Cbar%7Bk%7D'%2Cz'%5Cright)%5Clvert%20z%2C%20%5Cepsilon%5Cright%5D%5Cright%5C%7D" alt="V\left(k,\epsilon\lvert \bar{k}, z\right) = \underset{c,k'}{Max}\left\{U(c)+\beta E\left[V\left(k',\epsilon'| \bar{k}',z'\right)\lvert z, \epsilon\right]\right\}" />

subject to

<img src="https://tex.s2cms.ru/svg/c%20%2B%20k'%20%3D%20r%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%20k%20%2B%20w%5Cleft(%5Cbar%7Bk%7D%2C%20%5Cbar%7Bl%7D%2C%20z%5Cright)%5Ctilde%7Bl%7D%5Cepsilon%20%2B%20%5Cleft(1-%5Cdelta%5Cright)%20k" alt="c + k' = r\left(\bar{k}, \bar{l}, z\right) k + w\left(\bar{k}, \bar{l}, z\right)\tilde{l}\epsilon + \left(1-\delta\right) k" />

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D'%3D%20%5Calpha_0%20%2B%20%5Calpha_1%20%5Cbar%7Bk%7D%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_g" alt="log \bar{k}'= \alpha_0 + \alpha_1 \bar{k} \text{   if   } z=z_g" />

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D'%3D%20%5Cbeta_0%20%2B%20%5Cbeta_1%20%5Cbar%7Bk%7D%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_b" alt="log \bar{k}'= \beta_0 + \beta_1 \bar{k} \text{   if   } z=z_b" />

<img src="https://tex.s2cms.ru/svg/%20k'%20%5Cge%200%20" alt=" k' \ge 0 " />

<img src="https://tex.s2cms.ru/svg/%20c%20%3E%200%20" alt=" c &gt; 0 " />

<img src="https://tex.s2cms.ru/svg/%5Ctilde%7Bl%7D%3D1" alt="\tilde{l}=1" />

Den Haan (2010) classifies the main solutions to this problem in two types of algorithms: projection and perturbation methods.

Among the projection methods we have the classic approach by simulation of Krussel and Smith (1997, 1998) that is explained in more detail by Maliar, Maliar and Valli (2010), a numerical approach with a continuum of agents developed by Young (2010), the backward induction procedure develop by Reiter (2010), the parameterized distribution procedure of Algan, Allais, and Den Haan (2009), and the explicit aggregation algorithm developed by Haan and Rendahl (2009).

The introduction of perturbation methods as a way to solve this problem was initially developed by Preston and Roca (2006) with further modifications introduced by Kim, Kollmann, and Kim (2010), and a mixture of the perturbation and the projection method as presented in Reiter (2009).

More recent approaches as the ones presented in Fernandez-Villaverde, Hurtado, and Nuño (2019) allow the possibility of introducing neural-networks as a generalization of the Krussel and Smith approach.
According to Den Haan (2010) the computational complexity of efficiently coded algorithm is widespread with times of less than one second for the perturbation method of Kim et all (2010) all the way up to 2739 minutes for the parameterized expectation approach of Algan et. all (2009). The most stable solutions are given by the induction method of Reiter (2009) and the explicit aggregation algorithm of Den Haan (2009).  


## __2. Model Computation by numerical simulation (Krussel and Smith - 1997 and 1998; Maliar, Maliar and Valli - 2010)__

### __2.1 Environment Set-up__


```julia
using LinearAlgebra, Statistics, Distributions, Expectations, NLsolve, Roots;
using Random, Plots, Parameters, BenchmarkTools, ProgressMeter, LaTeXStrings;
using Profile, BenchmarkTools, Roots, NLsolve, ForwardDiff, Polynomials, Interpolations;
```

### __2.2 Parameter and Function specification__


```julia
u(c, σ) = σ == 1 ? log(c) : (c^(1 - σ)-1) / (1 - σ); # utility function
du(c, σ) = σ == 1 ? 1/c : (1/c^(σ)); # utilitu function derivative
F(K, L, z, α) = z * K^(α) * L^(1-α); # Production function
fK(K, L , z, α) = z * α * K^(α-1) * L^(1-α); # FOC for K
fL(K, L , z, α) = z * (1-α) * K^α * L^(-α); # FOC for L
Kr(r, L, z, α) = ((z*α)/r)^(1 / (1-α)) * L;
β = 0.99; # discount factor
σ = 1; # inverse of elasticity of substitution
cc = 0.01; # borrowing constraint
L = 5000; # Labour Force
a_max = 500; # Max level of asset holding
k_min = 20; # Min level of per capita capital
k_max = 100; # Max level of Per Capita capital
a_grid_size = 500; # Grid size for individual asset holding
k_grid_size =20; # Grid size for per capita aggregate capital
α = 0.36; # Share of capital in Cobb-Douglas
δ = 0.025; # Depreciation
θ = [β, σ, cc, L, a_max, k_max, a_grid_size, k_grid_size, α, δ]; # Vector of parameters
μg = 0.04; # Unemployment rate in good state
μb = 0.1; # Unemployment rate in bad state
μ = [μg; μb]; # Vector of unemployment rates
zg = 1.01; # Aggregate productivity in good state
zb = 0.99; # Aggregate productivity in bad state
z = [zg; zb]; # Vector of aggregate productivies
ϵg = 1; # Individual productivity if emploed
ϵb = 0; # Individual productivity if unemployed
ϵ = [ϵg; ϵb]; # Vector of individual productivities
Ω = [0.12 0.12; 0.96 0.96]; # Initial parameter guess for agg. law of motion
```

### __2.3 System of equations that solves Markov Process__

We specify the system of 20 equations that needs to be solved in order to define the Markov process


```julia
function g!(G, π)
    G[1] = π[1] + π[2] - π[3] - π[4]
    G[2] = π[1] + π[2] - π[5]
    G[3] = π[3] + π[4] - π[5]
    G[4] = π[6] + π[7] - π[8] - π[9]
    G[5] = π[6] + π[7] - π[10]
    G[6] = π[8] + π[9] - π[10]
    G[7] = π[11] + π[12] - π[13] - π[14]
    G[8] = π[11] + π[12] - π[15]
    G[9] = π[13] + π[14] - π[15]
    G[10] = π[16] + π[17] - π[18] - π[19]
    G[11] = π[16] + π[17] - π[20]
    G[12] = π[18] + π[19] - π[20]
    G[13] = μg * (π[1]/π[5]) + (1 - μg) * (π[3]/π[5]) - μg
    G[14] = μg * (π[6]/π[10]) + (1 - μg) * (π[8]/π[10]) - μb
    G[15] = μb * (π[11]/π[15]) + (1 - μb) * (π[13]/π[15]) - μg
    G[16] = μb * (π[16]/π[20]) + (1 - μb) * (π[18]/π[20]) - μb
    G[17] = π[5] + π[10] - 1
    G[18] = π[15] + π[20] - 1
    G[19] = (π[6]/π[10]) - 1.25 * (π[16]/π[20])
    G[20] = (π[11]/π[15]) - 0.75 * (π[1]/π[5])
end
πini = [0.25; 0.25; 0.25; 0.25; 0.5; 0.25; 0.25; 0.25; 0.25; 0.5; 0.25; 0.25; 0.25; 0.25; 0.5; 0.25; 0.25; 0.25; 0.25; 0.5];
G = nlsolve(g!, πini, autodiff = :forward);
π0 = G.zero;
(πgg00, πgg01, πgg10, πgg11, πgg, πgb00, πgb01, πgb10, πgb11, πgb, πbg00, πbg01, πbg10, πbg11, πbg, πbb00, πbb01, πbb10, πbb11, πbb) = π0;
Π = [πgg11 πgg10 πgb11 πgb10; πgg01 πgg00 πgb01 πgb00; πbg11 πbg10 πbb11 πbb10; πbg01 πbg00 πbb01 πbb00];
Λ = [πgg πgb; πbg πbb];
eigen(Λ); # Eigenvector of 1 implies that probability of good and bad aggregate shocks is equivalent;
@assert sum(Π, dims = 2) ≈ ones(4);
Π = [0.850694 0.024306 0.115885 0.009115; 0.583333 0.291667 0.03125 0.09375; 0.122917 0.002083 0.836111 0.038889; 0.09375 0.03125 0.35 0.525];
Λ = [0.955555 0.044445; 0.4 0.6]
```




The markov process for pair <img src="https://tex.s2cms.ru/svg/%5Cleft(z%2C%5Cepsilon%5Cright)" alt="\left(z,\epsilon\right)" /> is given by <img src="https://tex.s2cms.ru/svg/%5CPi" alt="\Pi" />. The order of the rows and columns is <img src="https://tex.s2cms.ru/svg/(z_g%2C%20%5Cepsilon_g)" alt="(z_g, \epsilon_g)" />, <img src="https://tex.s2cms.ru/svg/(z_g%2C%20%5Cepsilon_b)" alt="(z_g, \epsilon_b)" />, <img src="https://tex.s2cms.ru/svg/(z_b%2C%20%5Cepsilon_g)" alt="(z_b, \epsilon_g)" />, and <img src="https://tex.s2cms.ru/svg/(z_b%2C%20%5Cepsilon_b)" alt="(z_b, \epsilon_b)" />. Rows represent this period state and columns next period state.


```julia
@show Π
```



    4×4 Array{Float64,2}:
     0.850694  0.024306  0.115885  0.009115
     0.583333  0.291667  0.03125   0.09375
     0.122917  0.002083  0.836111  0.038889
     0.09375   0.03125   0.35      0.525   



The markov process for the aggregate state of the economy is given by $\Lambda$. The order of the rows is $z_g$ and $z_b$. Row represent this period state, and column next period state


```julia
@show Λ
```


    2×2 Array{Float64,2}:
     0.955555  0.044445
     0.4       0.6     



### __2.4 Policy Function__

We are going to define the function `KpolicyKS(u,du,θ,z,ϵ,Π,Ω)` with inputs:
- u: utility function
- du: derivative of utility function
- θ: vector of parameters previously defined
- z: vector of aggregate productivities
- ϵ: vector of idiosyncratic productivities
- Π: Markov process
- Ω: Matrix of parameters for the aggregate law of motion

__Steps for Value Function Iteration__

1. We use Maliar, Maliar, Valli (2009) algorithm for building a grid for <img src="https://tex.s2cms.ru/svg/a_t" alt="a_t" /> with more intervals in the lower values of <img src="https://tex.s2cms.ru/svg/a_t" alt="a_t" /> with the equation <img src="https://tex.s2cms.ru/svg/A%20%3D%20%5Cleft%5C%7Ba_j%20%3D%5Cleft(%5Cfrac%7Bj%7D%7BJ%7D%5Cright)%5E%5Crho%20a_%7Bmax%7D%5Cright%5C%7D" alt="A = \left\{a_j =\left(\frac{j}{J}\right)^\rho a_{max}\right\}" /> where <img src="https://tex.s2cms.ru/svg/J" alt="J" /> stands for grid size.
2. We define a value function of size <img src="https://tex.s2cms.ru/svg/k%5Ctext%7B%20grid%20size%7D%20%5Ctimes%20%5Cbar%7Bk%7D%5Ctext%7B%20grid%20size%7D%20%5Ctimes%20%5Ctext%7Bnumber%20of%20idiosyncratic%20productivity%20shocks%7D%5Ctimes%5Ctext%7B%20number%20of%20aggregate%20shocks%7D" alt="k\text{ grid size} \times \bar{k}\text{ grid size} \times \text{number of idiosyncratic productivity shocks}\times\text{ number of aggregate shocks}" />.
3. We iterate the value function using a linear interpolation algorithm for values of <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D_%7Bt%2B1%7D" alt="\bar{k}_{t+1}" /> that are not in the grid:

<img src="https://tex.s2cms.ru/svg/V%5E%7BN%2B1%7D%5Cleft(k_t%2C%5Cepsilon_t%5Cvert%20%5Cbar%7Bk%7D_t%2Cz_t%5Cright)%20%5Cequiv%20Max_%7Bk_%7Bt%2B1%7D%20%5Cin%20A%7D%5Cleft%5C%7BU%5Cleft(r%5Cleft(%5Cbar%7Bk%7D_t%2C%20(1-%5Cmu_%7Bz_t%7D)%2C%20z_t%5Cright)%20k_t%20%2B%20w%5Cleft(%5Cbar%7Bk%7D_t%2C%20(1-%5Cmu_%7Bz_t%7D)%2C%20z_t%5Cright)%5Cepsilon_t%20%5Cright." alt="V^{N+1}\left(k_t,\epsilon_t\vert \bar{k}_t,z_t\right) \equiv Max_{k_{t+1} \in A}\left\{U\left(r\left(\bar{k}_t, (1-\mu_{z_t}), z_t\right) k_t + w\left(\bar{k}_t, (1-\mu_{z_t}), z_t\right)\epsilon_t \right." />

<img src="https://tex.s2cms.ru/svg/%2B%20%5Cleft(1-%5Cdelta%5Cright)%20k_t-k_%7Bt%2B1%7D%5Cright)%2B%5Cbeta%20%5Csum_%7B%5Cforall%20(z%2C%5Cepsilon)%5Cin%20Z%20%5Ctimes%20E%7D%20%20V%5E%7BN%7D%5Cleft(k_%7Bt%2B1%7D%2C%5Cepsilon_%7Bt%2B1%7D%5Cvert%20%5Cbar%7Bk%7D_%7Bt%2B1%7D%2C%20z_%7Bt%2B1%7D%5Cright)Prob%5Cleft%5C%7Bz_%7Bt%2B1%7D%2C%5Cepsilon_%7Bt%2B1%7D%5Clvert%20z_%7Bt%7D%2C%5Cepsilon_%7Bt%7D%5Cright%5C%7D%5Cright%5C%7D" alt="+ \left(1-\delta\right) k_t-k_{t+1}\right)+\beta \sum_{\forall (z,\epsilon)\in Z \times E}  V^{N}\left(k_{t+1},\epsilon_{t+1}\vert \bar{k}_{t+1}, z_{t+1}\right)Prob\left\{z_{t+1},\epsilon_{t+1}\lvert z_{t},\epsilon_{t}\right\}\right\}" />

subject to

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D_%7Bt%2B1%7D%3D%20%5Calpha_0%20%2B%20%5Calpha_1%20%5Cbar%7Bk%7D_t%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_g" alt="log \bar{k}_{t+1}= \alpha_0 + \alpha_1 \bar{k}_t \text{   if   } z=z_g" />

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D_%7Bt%2B1%7D%3D%20%5Cbeta_0%20%2B%20%5Cbeta_1%20%5Cbar%7Bk%7D_t%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_b" alt="log \bar{k}_{t+1}= \beta_0 + \beta_1 \bar{k}_t \text{   if   } z=z_b" />

<img src="https://tex.s2cms.ru/svg/%20k_%7Bt%2B1%7D%20%5Cge%200%20" alt=" k_{t+1} \ge 0 " />

<img src="https://tex.s2cms.ru/svg/%20c_t%20%3E%200%20" alt=" c_t &gt; 0 " />

4. We iterate step 3 until the value function until <img src="https://tex.s2cms.ru/svg/sup%5Clvert%20V%5E%7BN%2B1%7D-V%5EN%20%5Clvert%3C1E%5E%7B-10%7D" alt="sup\lvert V^{N+1}-V^N \lvert&lt;1E^{-10}" />


*The maximum number of possible iterations is 100000, the minimum number of iterations is 100, we use $\rho =3$ and we control for the monotonicity of the policy function with respect to $k_t$*


```julia
function KpolicyKS(u, du, θ, μ, z, ϵ, Π, Ω; tol = 1E-10, max_iter = 100000, adj = 3, min_iter = 100, control = 1)
    # u : utility function
    # du : derivative of the utility function with respect to c
    # θ : vector of relevant parameters
    # μ : vector of unemployment rates in the different states
    # z : vector of aggregate shocks
    # ϵ : vector of individual shocks. in this case, employed or unemployed.
    # Π : markov process matrix for the individual (aggregate-individual states)
    # Λ : markov provess for the aggregate economy
    start = time();
    println("      Kpolicy(Krussel & Smith)...")
    # Extract and define the internal parameters
    β, σ, cc, L, a_max, k_max, a_grid_size, k_grid_size, α, δ= θ[1], θ[2], θ[3], θ[4], θ[5], θ[6], convert(Int,θ[7]), convert(Int,θ[8]), θ[9], θ[10];
    b = cc;
    # Borrowing constraint as defined in Aiyagari (p. 666)
    φ = -b; #r > 0 ? min(b, w*Y[1] / r) : b;
    # Grid for with logarithmic adjustment - more weight to lower values of a by decreasing adj
    a_grid = cc .+ [(p/a_grid_size)^adj * (a_max-cc) for p in 1:a_grid_size];
    k_grid = collect(range(k_min, k_max, length = k_grid_size));
    # We find the number of aggregate shocks and idiosincratic shocks
    num_agg_shock = size(z)[1];
    num_idi_shock = size(μ)[1];
    # We define the initial matrices for the iteration:
    #  V (Value Function); Ind(Indicator of policy function); A_prime (Policy function)
    sup = Inf;
    V1 = zeros(a_grid_size, k_grid_size, num_idi_shock, num_agg_shock);
    Ind1 = convert.(Int,ones(size(V1)));
    for s ∈ 1 : num_agg_shock
        for j ∈ 1 : k_grid_size
            for r ∈ 1 : num_idi_shock
                for i ∈ 1 : a_grid_size
                    V1[i,j,r,s] = sqrt(i)
                    Ind1[i,j,r,s] =  max(floor(0.9 * i), 1.0)
                end
            end
        end
    end
    Ind1 = convert.(Int, Ind1)
    A_prime1 = zeros(size(Ind1));
    A_prime1 = a_grid[Ind1];
    # With all the possible prices for the aggregate state we procede to iterate the policy function.
    iter = 0;
    while (sup > tol && iter <= max_iter) | (iter < min_iter)
        iter += 1;
        V0 = copy(V1);
        Ind0 = copy(Ind1);
        A_prime0 = copy(A_prime1);

        knots = (a_grid, k_grid);#([a_grid[p] for p = 1:a_grid_size], [k_grid[q] for 1:k_grid_size])
        V11 = interpolate(knots, V0[:,:,1,1], Gridded(Linear()))
        V21 = interpolate(knots, V0[:,:,2,1], Gridded(Linear()))
        V12 = interpolate(knots, V0[:,:,1,2], Gridded(Linear()))
        V22 = interpolate(knots, V0[:,:,2,2], Gridded(Linear()))

        # 4 dimensional matrices of size (a_grid_size, k_grid_size, num_idi_shock, num_agg_shock) with indicators ( i, j, r, s) where:
            # i : position in the a_grid
            # j : position in the K_grid (grid for the aggregate capital)
            # r : idiosincratic shock
            # s : Aggregate shock.
        for s ∈ 1 : num_agg_shock
            for r ∈ 1 : num_idi_shock
                for j ∈ 1 : k_grid_size
                    K_pre = exp(([1 log(k_grid[j])] * Ω[:,s])[1]);
                    # We locate the position in the grid of the closest point that is just above to the prediction level of capital
                    ind_k = max(min((k_grid[findmin(abs.(k_grid .- K_pre))[2]] > K_pre) ? (findmin(abs.(k_grid .- K_pre))[2]) : (findmin(abs.(k_grid .- K_pre))[2] + 1), k_grid_size),2);
                    # position_K_pre finds the linearly interpolate value of K_pre
                    H = [V11(a_grid,K_pre) V21(a_grid,K_pre) V12(a_grid,K_pre) V22(a_grid,K_pre)];
                    for i ∈ 1 : a_grid_size
                        # Prediction of the mean of the aggregate state at the next period. This is going to be used for evaluating the expectations for the next step. With the prediction I find the closest point in the grid point and identify its position with ind_k. With this ind_k I can build two submatrices of the value function that allow its estimation:
                        # H : submatrix that takes the 4 vector out of V that have ind_k
                        #       [(:, ind_k, ϵg, zg) (:, ind_k, ϵb, zg) (:, ind_k, ϵg, zb) (:, ind_k, ϵb, zb)]
                        #       [(1, ind_k, ϵg, zg) (1, ind_k, ϵb, zg) (1, ind_k, ϵg, zb) (1, ind_k, ϵb, zb)]
                        # The indicator g is going to identify in which of the 4 possible combinations of idiosincratic and aggregate shock I'm going to find myself. (1 : employed-boom, 2 : unemployed - boom, 3 : employed - bust ; 4 : unemployed - bust)
                        if s == 1 && r == 1
                            g = 1
                        elseif s == 1 && r == 2
                            g = 2
                        elseif (s == 2 && r == 1)
                            g = 3
                        elseif s == 2 && r == 2
                            g = 4
                        end
                        # We proceed to evaluate the max of the value function taking the policy function as given. With this max we build a new policy function.
                        V1[i,j,r,s], Ind1[i,j,r,s]  = findmax(u.(max.(fK(k_grid[j], (1 - μ[s]), z[s], α) * a_grid[i] .+ fL(k_grid[j], (1 - μ[s]), z[s], α)  * ϵ[r] .+ (1 - δ) * a_grid[i] .- a_grid, 1E-300), σ) .+ β * H * Π[g,:]);
                    end
                end
            end
        end
        A_prime1 = a_grid[Ind1];
        sup = maximum((abs.(V0 - V1) .< Inf) .* abs.(V0 - V1));
        #@show iter, sup # Activate if you want to see convergence of value function
    end
    A_prime = A_prime1
    Ind = Ind1
    row = 1
    s = 1
    while s == 1
        if maximum(A_prime[row,:,:,:]) ==  a_max
            for s ∈ 1 : num_agg_shock
                for r ∈ 1 : num_idi_shock
                    A_prime[row,:,r,s] = transpose(A_prime[row,:,r,s] .!= a_max) .* transpose(A_prime[row,:,r,s]) + transpose(A_prime[row,:,r,s] .== a_max) .* (minimum(A_prime[row,:,r,s]));
                    Ind[row,:,r,s] = transpose(A_prime[row,:,r,s] .!= a_max) .* transpose(Ind[row,:,r,s]) + transpose(A_prime[row,:,r,s] .== a_max) .* (findmin(minimum(A_prime[row,:,r,s]) .- a_grid)[2]);
                end
            end
            row = row + 1
        else
            s = 0
        end
    end
    V = V1
    a_grid = a_grid
    k_grid = k_grid
    if control == 1
        #Check whether for each one of the four possible states the policy function is increasing
        @assert findmax(A_prime[:,:,1,1], dims=1)[1] ≈ transpose(A_prime[end,:, 1, 1]) "Final row of A' does not coincide for zg and ϵg. Most likely solution: increase the k_min"
        @assert findmax(A_prime[:,:,2,1], dims=1)[1] ≈ transpose(A_prime[end,:, 2, 1]) "Final row of A' does not coincide for zg and ϵl. Most likely solution: increase the k_min"
        @assert findmax(A_prime[:,:,1,2], dims=1)[1] ≈ transpose(A_prime[end,:, 1, 2]) "Final row of A' does not coincide for zb and ϵg. Most likely solution: increase the k_min"
        @assert findmax(A_prime[:,:,2,2], dims=1)[1] ≈ transpose(A_prime[end,:, 2, 2]) "Final row of A' does not coincide for zl and ϵl. Most likely solution: increase the k_min"
    end
    elapsed = time() - start
    println("         Kpolicy solved in $iter iter, with a sup metric of $sup and in $elapsed seconds")
    return sol = [A_prime, a_grid, k_grid, Ind, V]
end
```




    KpolicyKS (generic function with 1 method)




```julia
VFI = KpolicyKS(u, du, θ, μ, z, ϵ, Π, Ω);
```

          Kpolicy(Krussel & Smith)...
             Kpolicy solved in 2377 iter, with a sup metric of 9.910650078381877e-11 and in 1391.8949999809265 seconds


### __2.4.1 Policy Function__

The policy function <img src="https://tex.s2cms.ru/svg/f" alt="f" /> in state <img src="https://tex.s2cms.ru/svg/z_g" alt="z_g" /> for an employed and unemployed household with <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D%5Capprox%2040" alt="\bar{k}\approx 40" /> (closest value to equilibrium in grid) shows that employed households save more. The same conclusion holds for state <img src="https://tex.s2cms.ru/svg/z_b" alt="z_b" />


```julia
plot(VFI[2],[VFI[1][:,15,1,1] VFI[1][:,15,2,1]], title ="Policy Function",xlabel="Individual Capital at t", ylabel="Individual Capital at t+1", legend=:bottomright, label=["Employed in Boom" "Unemployed in Boom"])
```




![svg](/Krusell_and_Smith(1998)_files/output_33_0.svg)



Savings from employed household during a boom are higher than during a bust


```julia
plot(VFI[2],[VFI[1][:,15,1,1] VFI[1][:,15,1,2]], title ="Policy Function",xlabel="Individual Capital at t", ylabel="Individual Capital at t+1", legend=:bottomright, label=["Employed in Boom" "Employed in Bust"])
```




![svg](/Krusell_and_Smith(1998)_files/output_35_0.svg)



On the other hand, the behaviour of an unemployed household is symmetric independent of the state of the economy


```julia
plot(VFI[2],[VFI[1][:,15,2,1] VFI[1][:,15,2,2]], title ="Policy Function",xlabel="Individual Capital at t", ylabel="Individual Capital at t+1", legend=:bottomright, label=["Unemployed in Boom" "Unemployed in Bust"])
```




![svg](/Krusell_and_Smith(1998)_files/output_37_0.svg)



For an indiosincratic level of saving of <img src="https://tex.s2cms.ru/svg/k%20%5Capprox%2040" alt="k \approx 40" /> we have that households are going to save less as the aggregate capital <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D" alt="\bar{k}" /> increases because as <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D" alt="\bar{k}" /> increases the expected return in current savings is going to be reduced


```julia
plot(VFI[3],[VFI[1][73,:,1,1] VFI[1][73,:,2,1] VFI[1][73,:,1,2] VFI[1][73,:,2,2]], title ="Policy Function",xlabel="Aggregate Capital at t", ylabel=" Individual Capital at t+1", legend=:bottomright, label=["Employed in Boom" "Unemployed in Boom" "Employed in Bust" "Unemployed in Bust"])
```




![svg](/Krusell_and_Smith(1998)_files/output_39_0.svg)



### __2.4.2 Value Function__

Concavity of value function and monotonicity with respect to the idiosyncratic shock at <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D%5Capprox40" alt="\bar{k}\approx40" />. The value function difference between employed in boom and bust is imperceptible.



```julia
plot(VFI[2],[VFI[5][:,15,1,1] VFI[5][:,15,2,1] VFI[5][:,15,1,2] VFI[5][:,15,2,2]], title ="Value Function",xlabel="Individual Capital at t", ylabel="Value Function", legend=:bottomright, label=["Employed in Boom" "Unemployed in Boom" "Employed in Bust" "Unemployed in Bust"])
```




![svg](/Krusell_and_Smith(1998)_files/output_44_0.svg)



For an indiosincratic level of saving of <img src="https://tex.s2cms.ru/svg/k%5Capprox%2040" alt="k\approx 40" /> the aggregate capital increases the value function decreases due to the reduction in the expect profit of savings. The value function of employed households are approximately similar between boom and busts.

Of interest is the fact that unemployed households are better of during the bust. An explanation might be that lower current profits on capital might


```julia
plot(VFI[3],[VFI[5][73,:,1,1] VFI[5][73,:,2,1] VFI[5][73,:,1,2] VFI[5][73,:,2,2]], title ="Value Function",xlabel="Aggregate Capital at t", ylabel="Value Function", legend=:topright, label=["Employed in Boom" "Unemployed in Boom" "Employed in Bust" "Unemployed in Bust"])
```




![svg](/Krusell_and_Smith(1998)_files/output_46_0.svg)



### __2.5 Equilibrium Algorithm__

The function `KlevelKS` takes the same inputs as the function `KSpolicy`and estimates:

- The individal level of asset holdings for each household under the different stationary distributions for the different types of aggregate shocks.
- The equilibrium interest rate in each one of the aggregate states under the different stationary distributions.
- The parameters <img src="https://tex.s2cms.ru/svg/%5Calpha" alt="\alpha" /> and <img src="https://tex.s2cms.ru/svg/%5Cbeta" alt="\beta" /> that characterize the aggregate law of motion of capital and its <img src="https://tex.s2cms.ru/svg/R%5E2" alt="R^2" /> and standard deviation of the residual.

This is done with the following algorithm

__Steps for Convergence in Stationary Distribution__

1. From the `Kpolicy` function do an initial extraction of the policy function, the grid on <img src="https://tex.s2cms.ru/svg/k" alt="k" /> and the grid on <img src="https://tex.s2cms.ru/svg/%5Cbar%7Bk%7D" alt="\bar{k}" />.
2. Randomly assign an initial level of assets <img src="https://tex.s2cms.ru/svg/a_0" alt="a_0" /> to all individuals, an aggregate state <img src="https://tex.s2cms.ru/svg/z" alt="z" />, and a distribution of individual productivity <img src="https://tex.s2cms.ru/svg/%5Cepsilon" alt="\epsilon" /> with an unemployment rate <img src="https://tex.s2cms.ru/svg/%5Cmu_z" alt="\mu_z" /> that matches the unemployment rate for the state <img src="https://tex.s2cms.ru/svg/z" alt="z" />. In order to match the unemployment rate <img src="https://tex.s2cms.ru/svg/%5Cmu_z" alt="\mu_z" /> do a random assignment of <img src="https://tex.s2cms.ru/svg/%5Cepsilon" alt="\epsilon" /> and modify the number of individuals that is necessary to get <img src="https://tex.s2cms.ru/svg/%5Cmu_z" alt="\mu_z" />.
3. Conditional on the Markov process probabilities iterate for <img src="https://tex.s2cms.ru/svg/T" alt="T" /> periods the aggregate shock <img src="https://tex.s2cms.ru/svg/z_g" alt="z_g" /> and conditional on aggregate shock transition <img src="https://tex.s2cms.ru/svg/z_g%2C%20z_g'" alt="z_g, z_g'" /> assign <img src="https://tex.s2cms.ru/svg/%5Cepsilon" alt="\epsilon" /> in a way that is consistent with the unemployment rate <img src="https://tex.s2cms.ru/svg/%5Cmu_z" alt="\mu_z" /> of the aggregate state of the economy. Let each household choose in each period their levels of asset holdings <img src="https://tex.s2cms.ru/svg/k" alt="k" /> and consumption <img src="https://tex.s2cms.ru/svg/c" alt="c" />. Iterate in this step until the distribution of assets converge in the first three moments of the distribution, i.e.:

<img src="https://tex.s2cms.ru/svg/Max%5Cleft%5C%7BMax%5Cleft%5C%7BE%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cg%7D-E%5Cleft%5Bk%5Cright%5D_%7Bt%2Cg%7D%3B%20E%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cb%7D-E%5Cleft%5Bk%5Cright%5D_%7Bt%2Cb%7D%5Cright%5C%7D%5E2%2C%5Cright." alt="Max\left\{Max\left\{E\left[k\right]_{t+1,g}-E\left[k\right]_{t,g}; E\left[k\right]_{t+1,b}-E\left[k\right]_{t,b}\right\}^2,\right." />

<img src="https://tex.s2cms.ru/svg/Max%5Cleft%5C%7BSd%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cg%7D-Sd%5Cleft%5Bk%5Cright%5D_%7Bt%2Cg%7D%3B%20Sd%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cb%7D-Sd%5Cleft%5Bk%5Cright%5D_%7Bt%2Cb%7D%5Cright%5C%7D%5E2%2C" alt="Max\left\{Sd\left[k\right]_{t+1,g}-Sd\left[k\right]_{t,g}; Sd\left[k\right]_{t+1,b}-Sd\left[k\right]_{t,b}\right\}^2," />

<img src="https://tex.s2cms.ru/svg/%5Cleft.Max%5Cleft%5C%7BSkw%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cg%7D-Skw%5Cleft%5Bk%5Cright%5D_%7Bt%2Cg%7D%3B%20Skw%5Cleft%5Bk%5Cright%5D_%7Bt%2B1%2Cb%7D-Skw%5Cleft%5Bk%5Cright%5D_%7Bt%2Cb%7D%5Cright%5C%7D%5E2%5Cright%5C%7D%3C%201E%5E%7B-7%7D" alt="\left.Max\left\{Skw\left[k\right]_{t+1,g}-Skw\left[k\right]_{t,g}; Skw\left[k\right]_{t+1,b}-Skw\left[k\right]_{t,b}\right\}^2\right\}&lt; 1E^{-7}" />

where <img src="https://tex.s2cms.ru/svg/t" alt="t" /> and <img src="https://tex.s2cms.ru/svg/t%2B1" alt="t+1" /> do not necessarily stand for subsequent periods, but for subsequent periods with the same aggregate state.
4. Iterate step 3 for at least 1000 periods and at most 10000 periods and burn in the first 500 period in order to avoid the effects of the initial assignment of capital. Estimate the linear regressions:

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D'%3D%20%5Calpha_0%20%2B%20%5Calpha_1%20%5Cbar%7Bk%7D%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_g" alt="log \bar{k}'= \alpha_0 + \alpha_1 \bar{k} \text{   if   } z=z_g" />

<img src="https://tex.s2cms.ru/svg/log%20%5Cbar%7Bk%7D'%3D%20%5Cbeta_0%20%2B%20%5Cbeta_1%20%5Cbar%7Bk%7D%20%5Ctext%7B%20%20%20if%20%20%20%7D%20z%3Dz_b" alt="log \bar{k}'= \beta_0 + \beta_1 \bar{k} \text{   if   } z=z_b" />

and stop if

<img src="https://tex.s2cms.ru/svg/Mean%5Cleft%5C%7B%5COmega_1%20-%20%5COmega_0%5Cright%5C%7D%3DMean%5Cleft%5C%7B%5Cbegin%7Bbmatrix%7D%5Calpha_%7B0%2C1%7D%20%26%20%5Cbeta_%7B0%2C1%7D%20%5C%5C%20%5Calpha_%7B1%2C1%7D%20%26%20%5Cbeta_%7B1%2C1%7D%20%5Cend%7Bbmatrix%7D%20-%20%5Cbegin%7Bbmatrix%7D%5Calpha_%7B0%2C0%7D%20%26%20%5Cbeta_%7B0%2C0%7D%20%5C%5C%20%5Calpha_%7B1%2C0%7D%20%26%20%5Cbeta_%7B1%2C0%7D%20%5Cend%7Bbmatrix%7D%5Cright%5C%7D%3C1E%5E%7B-7%7D" alt="Mean\left\{\Omega_1 - \Omega_0\right\}=Mean\left\{\begin{bmatrix}\alpha_{0,1} &amp; \beta_{0,1} \\ \alpha_{1,1} &amp; \beta_{1,1} \end{bmatrix} - \begin{bmatrix}\alpha_{0,0} &amp; \beta_{0,0} \\ \alpha_{1,0} &amp; \beta_{1,0} \end{bmatrix}\right\}&lt;1E^{-7}" />

and

<img src="https://tex.s2cms.ru/svg/Min%5Cleft%5C%7BR%5E2_g%2C%20R%5E2_b%5Cright%5C%7D%3E%200.99" alt="Min\left\{R^2_g, R^2_b\right\}&gt; 0.99" />

otherwise repeat a estimation from step one using:

<img src="https://tex.s2cms.ru/svg/%5COmega%20%3D%20%5COmega_0%20%5Ctimes%20%5Cfrac%7Biteration%7D%7Biteration%20%2B%201%7D%20%2B%20%5COmega_1%20%5Ctimes%20%5Cfrac%7B1%7D%7Biteration%20%2B%201%7D" alt="\Omega = \Omega_0 \times \frac{iteration}{iteration + 1} + \Omega_1 \times \frac{1}{iteration + 1}" />

which should converge to the true set of parameters by unbiasedness of OLS


```julia
function KlevelKS(u, du, θ, μ, z, ϵ, Π, Ω; tol = 1E-7, tolβ = 1E-7, max_iter_dist = 11000, min_iter_dist = 1000, max_iter_β = 100, burn_in_dist = 500, R2min = 0.99)
    start = time();
    println("   Klevel(Krusell & Smith)...")
    # Extract and define the internal parameters
    β, σ, cc, L, a_max, k_max, a_grid_size, k_grid_size, α, δ= θ[1], θ[2], θ[3], convert(Int,θ[4]), θ[5], θ[6], convert(Int,θ[7]), convert(Int,θ[8]), θ[9], θ[10];
    KpolicyKS_sol = KpolicyKS(u, du, θ, μ, z, ϵ, Π, Ω);
    A_prime = KpolicyKS_sol[1];
    a_grid = KpolicyKS_sol[2];
    k_grid = KpolicyKS_sol[3];
    Ind = KpolicyKS_sol[4];
    V = KpolicyKS_sol[5];
    # Verify if crossing of the policy function with high productivity and the 45 degree line
    @assert minimum(A_prime[:,:,1,1] .- a_grid) ≤ 0 "No crossing with 45 degree Line"
    # We build the elements conditional in the max level of savings at the steady state. The one that just crosses the 45 degree line
    lim_ind_a = size(a_grid)[1];
    a_sup = a_grid[lim_ind_a];
    lim_ind_k = size(k_grid)[1];
    new_a_grid = a_grid[1:lim_ind_a];
    new_k_grid = k_grid[1:lim_ind_k];
    dim_a = size(new_a_grid)[1];
    dim_k = size(new_k_grid)[1];
    new_A_prime = A_prime[1:lim_ind_a, 1:lim_ind_k, :, :];
    new_V = V[1:lim_ind_a, 1:lim_ind_k, :, :];
    new_Ind = Ind[1:lim_ind_a, 1:lim_ind_k, :, :];
    # Initial Condition
    # Let's establish that everybody starts at a middle capital level.
    inda0 = fill(findmin((abs.(k_grid[convert(Int,max(floor(dim_k/2),1))] .- a_grid)))[2], L, 1);
    A0 = new_a_grid[inda0];
    # We start in a random Aggregate State. And once that random aggegate state has been given we allocate job positions and adjust the number of workers to satisfy the unemployment rate at each one of the different aggregate states
    # If ϵ[n] = 1 it means that consumer n is working
    z0 = rand(Bernoulli(0.5), 1)==1 ? zg : zb;
    if z0 == zg
        ϵ0 = [rand(Bernoulli(1-μg)) == 1 ? ϵg : ϵb for p=1:L];
        ind = 0;
        while sum(ϵ0 .== ϵb)/L ≠ μg && ind < L;
            ind += 1
            if sum(ϵ0 .== ϵb)/L > μg
                if ϵ0[ind] == ϵb
                    ϵ0[ind] = ϵg
                end
            elseif sum(ϵ0 .== ϵb)/L < μg
                if ϵ0[ind] == ϵg
                    ϵ0[ind] = ϵb
                end
            end
        end
    elseif z0 == zb
        ϵ0 = [rand(Bernoulli(1-μb)) == 1 ? ϵg : ϵb for p=1:L];
        ind = 0;
        while sum(ϵ0 .== ϵb)/L ≠ μb && ind ≤ L;
            ind += 1
            if sum(ϵ0 .== ϵb)/L > μb
                if ϵ0[ind] == ϵb
                    ϵ0[ind] = ϵg
                end
            elseif sum(ϵ0 .== ϵb)/L < μb
                if ϵ0[ind] == ϵg
                    ϵ0[ind] = ϵb
                end
            end
        end
    end
    # With the initial level of capital we establish which is the initial aggregate level of capital
    indk0 =findmin(abs.(mean(A0) .- new_k_grid))[2]
    k0 = new_k_grid[indk0]
    iterβ = 0;
    z1 = z0;
    A1 = A0;
    ϵ1 = ϵ0;
    k1 = k0;
    μ1g = Inf;
    σ1g = Inf;
    sk1g = Inf;
    μ1b = Inf;
    σ1b = Inf;
    sk1b = Inf;
    supβ = Inf;
    supdist = Inf;
    R2g = 0.0;
    R2b = 0.0;
    σg = 1.0;
    σb = 1.0;
    Ω1 = Ω;
    while (((supβ > tolβ) | (min(R2g, R2b) < R2min)) && (iterβ ≤ max_iter_β))
        iter_dist = 0
        indicator_g = 1
        indicator_b = 1
        Yg = zeros(1);
        Xg = zeros(1);
        Yb = zeros(1);
        Xb = zeros(1);
        Ω0 = copy(Ω1)
        Ω1 = zeros(size(Ω0));
        R2g = R2g;
        R2b = R2b;
        σg = σg;
        σb = σb;
        A1g = zeros(size(A1));
        A1b = zeros(size(A1));
        ϵ1g = zeros(size(ϵ1));;
        ϵ1b = zeros(size(ϵ1));
        while (supdist > tol && iter_dist ≤ max_iter_dist) | (iter_dist < min_iter_dist)
            z0 = copy(z1);
            k0 = copy(k1);
            k1 = 0.0;
            A0 = copy(A1);
            A1 = zeros(size(A0));
            A1g = copy(A1g);
            A1b = copy(A1b);
            ϵ0 = copy(ϵ1);
            ϵ1 = zeros(size(ϵ0));
            ϵ1g = copy(ϵ1g);
            ϵ1b = copy(ϵ1b);
            μ0g = copy(μ1g);
            μ0b = copy(μ1b);
            σ0g = copy(σ1g);
            σ0b = copy(σ1b);
            sk0g = copy(sk1g);
            sk0b = copy(sk1b);
            # z0 : state in t
            if z0 == zg
                # given z0 in t, in t+1 the economy will find itself in state zg with probability π(z0,g) and in zb with probability 1-π(z0,b)
                z1 = rand(Bernoulli(Λ[1,1])) == 1 ? zg : zb;
                # z0 and idiosincratic state ϵ0 in t, and state z1 in t+1 the agent will find itself employed in t with probability π(z0,z1)(ϵ1,ϵg) and unemployed with probability 1-π(z0,z1)(ϵ1,ϵg). We also guarantee that the aggregate unemployment coincides with the μ(z1)
                if z1 == zg
                    ϵ1 = (ϵ0 .== ϵg) .* [rand(Bernoulli(Π[1,1])) == 1 ? ϵg : ϵb for p=1:L] +
                         (ϵ0 .== ϵb) .* [rand(Bernoulli(Π[2,1])) == 1 ? ϵg : ϵb for p=1:L];
                    ind = 0;
                    while sum(ϵ1 .== ϵb)/L ≠ μg && ind < L;
                        ind += 1
                        if sum(ϵ1 .== ϵb)/L > μg
                            if ϵ1[ind] == ϵb
                                ϵ1[ind] = ϵg
                            end
                        elseif sum(ϵ1 .== ϵb)/L < μg
                            if ϵ1[ind] == ϵg
                                ϵ1[ind] = ϵb
                            end
                        end
                    end
                elseif z1 == zb
                    ϵ1 = (ϵ0 .== ϵg) .* [rand(Bernoulli(Π[1,3])) == 1 ? ϵg : ϵb for p=1:L] +
                         (ϵ0 .== ϵb) .* [rand(Bernoulli(Π[2,3])) == 1 ? ϵg : ϵb for p=1:L];
                    ind = 0;
                    while sum(ϵ1 .== ϵb)/L ≠ μb && ind ≤ L;
                        ind += 1
                        if sum(ϵ1 .== ϵb)/L > μb
                            if ϵ1[ind] == ϵb
                                ϵ1[ind] = ϵg
                            end
                        elseif sum(ϵ1 .== ϵb)/L < μb
                            if ϵ1[ind] == ϵg
                                ϵ1[ind] = ϵb
                            end
                        end
                    end
                end
                ϵ1g = ϵ1
                # Given aggregate state z0, idiosincratic state ϵ0, and current aggregate capital k0, the distribution of capital in t+1 is given by
                for i ∈ 1:dim_a
                    for j ∈ 1:dim_k
                        A1 += (k0 == new_k_grid[j]) * (A0 .== new_a_grid[i]) .* (((ϵ0 .== ϵg) * new_A_prime[i,j,1,1]) + ((ϵ0 .== ϵb) * new_A_prime[i,j,2,1]));
                    end
                end
                k1 = new_k_grid[findmin(abs.(mean(A1).- new_k_grid))[2]]
                μ1g = mean(A1)
                σ1g = sqrt(var(A1))
                sk1g = skewness(A1)
                A1g = A1

                if ((indicator_g == 1) && (iter_dist ≥ burn_in_dist))
                    Xg = log(mean(A0))
                    Yg = log(mean(A1))
                    indicator_g = 0
                elseif ((indicator_g == 0) && (iter_dist ≥ burn_in_dist))
                    Xg = vcat(Xg, log(mean(A0)))
                    Yg = vcat(Yg, log(mean(A1)))
                end
            elseif z0 == zb
                # given z0 in t-1, in t the economy will find itself in state zg with probability π(z0,g) and in zb with probability 1-π(z0,b)
                z1 = rand(Bernoulli(Λ[2,2])) == 1 ? zb : zg;
                # z0 and idiosincratic state ϵ0 in t-1, and state z1 in tm the agent will find itself employed in t with probability π(z0,z1)(ϵ1,ϵg) and unemployed with probability 1-π(z0,z1)(ϵ1,ϵg). We also guarantee that the aggregate unemployment coincides with the μ(z1)
                if z1 == zg
                    ϵ1 = (ϵ0 .== ϵg) .* [rand(Bernoulli(Π[3,1])) == 1 ? ϵg : ϵb for p=1:L] +
                         (ϵ0 .== ϵb) .* [rand(Bernoulli(Π[4,1])) == 1 ? ϵg : ϵb for p=1:L];
                    ind = 0;
                    while sum(ϵ1 .== ϵb)/L ≠ μg && ind < L;
                        ind += 1
                        if sum(ϵ1 .== ϵb)/L > μg
                            if ϵ1[ind] == ϵb
                                ϵ1[ind] = ϵg
                            end
                        elseif sum(ϵ1 .== ϵb)/L < μg
                            if ϵ1[ind] == ϵg
                                ϵ1[ind] = ϵb
                            end
                        end
                    end
                elseif z1 == zb
                    ϵ1 = (ϵ0 .== ϵg) .* [rand(Bernoulli(Π[3,3])) == 1 ? ϵg : ϵb for p=1:L] +
                         (ϵ0 .== ϵb) .* [rand(Bernoulli(Π[4,3])) == 1 ? ϵg : ϵb for p=1:L];
                    ind = 0;
                    while sum(ϵ1 .== ϵb)/L ≠ μb && ind ≤ L;
                        ind += 1
                        if sum(ϵ1 .== ϵb)/L > μb
                            if ϵ1[ind] == ϵb
                                ϵ1[ind] = ϵg
                            end
                        elseif sum(ϵ1 .== ϵb)/L < μb
                            if ϵ1[ind] == ϵg
                                ϵ1[ind] = ϵb
                            end
                        end
                    end
                end
                ϵ1b = ϵ1
                # Given aggregate state z0, idiosincratic state ϵ0, and current aggregate capital k0, the distribution of capital in t+1 is given by
                for i ∈ 1:dim_a
                    for j ∈ 1:dim_k
                        A1 += (k0 == new_k_grid[j]) * (A0 .== new_a_grid[i]) .* (((ϵ0 .== ϵg) * new_A_prime[i,j,1,2]) + ((ϵ0 .== ϵb) * new_A_prime[i,j,2,2]));
                    end
                end
                k1 = new_k_grid[findmin(abs.(mean(A1) .- new_k_grid))[2]]
                μ1b = mean(A1)
                σ1b = sqrt(var(A1))
                sk1b = skewness(A1)
                A1b = A1

                if ((indicator_b == 1) && (iter_dist ≥ burn_in_dist))
                    Xb = log(mean(A0))
                    Yb = log(mean(A1))
                    indicator_b = 0
                elseif ((indicator_b == 0) && (iter_dist ≥ burn_in_dist))
                    Xb = vcat(Xb, log(mean(A0)))
                    Yb = vcat(Yb, log(mean(A1)))
                end
            end
            supdist = maximum([max(μ1g - μ0g, μ1b - μ0b) max(σ1g - σ0g, σ1b - σ0b) max(sk1g - sk0g, sk1b - sk0b)].^2)
            iter_dist += 1;
            #@show iter_dist, supdist
        end
        A1g = A1g
        A1b = A1b
        ϵ1g = ϵ1g
        ϵ1b = ϵ1b
        Yg = Yg
        Yb = Yb
        Xg = Xg
        Xb = Xb
        KSg = exp(Xg[end])
        KSb = exp(Xb[end])
        rg = fK(KSg, (1 - μg), zg, α)
        rb = fK(KSb, (1 - μb), zg, α)
        Ω1[:,1] = (transpose([ones(size(Xg)) Xg]) * [ones(size(Xg)) Xg]) \ (transpose([ones(size(Xg)) Xg]) * Yg)
        R2g = (sum(([ones(size(Xg)) Xg]*Ω1[:,1] .- mean(Yg)).^2)/sum((Yg .- mean(Yg)).^2))
        R2g = 0 ≤ R2g ≤ 1 ? R2g : 0
        σg = sqrt(sum((Yg .- [ones(size(Xg)) Xg]*Ω1[:,1]).^2)/(size(Yg)[1]-2))
        Ω1[:,2] = (transpose([ones(size(Xb)) Xb]) * [ones(size(Xb)) Xb]) \ (transpose([ones(size(Xb)) Xb]) * Yb)
        R2b = (sum(([ones(size(Xb)) Xb]*Ω1[:,2] .- mean(Yb)).^2)/sum((Yb .- mean(Yb)).^2))
        R2b = 0 ≤ R2b ≤ 1 ? R2b : 0
        σb = sqrt(sum((Yb .- [ones(size(Xb)) Xb]*Ω1[:,2]).^2)/(size(Yb)[1]-2))
        Ω1[:,1] = (Ω0[:,1]*(iterβ)/(iterβ+1)) + (Ω1[:,1] /(iterβ+1));
        Ω1[:,2] = (Ω0[:,2]*(iterβ)/(iterβ+1)) + (Ω1[:,2] /(iterβ+1));
        supβ = isnan(mean((Ω1 - Ω0).^2)) == 0 ? mean((Ω1 - Ω0).^2) : Inf
        iterβ += 1;
        println("            Kpolicy has iterated $iterβ times  with a sup metric of $supβ")
        println("               and with (R2g, σg) = ($R2g,$σg); (R2b, σb) = ($R2b,$σb)")
        println("                  dist. conv. in $iter_dist ite with a sup metric of $supdist.")
        println("                  Ω = $Ω1.")
        println("                  (Kg, rg) = ($KSg, $rg) and (Kb, rb) = ($KSb, $rb).")
        if (((supβ > tolβ) | (min(R2g, R2b) < R2min)) && (iterβ ≤ max_iter_β))
            KpolicyKS_sol = KpolicyKS(u, du, θ, μ, z, ϵ, Π, Ω1);
            A_prime = KpolicyKS_sol[1];
            a_grid = KpolicyKS_sol[2];
            k_grid = KpolicyKS_sol[3];
            Ind = KpolicyKS_sol[4];
            V = KpolicyKS_sol[5];
            # Verify if crossing of the policy function with high productivity and the 45 degree line
            @assert minimum(A_prime[:,:,1,1] .- a_grid) ≤ 0 "No crossing with 45 degree Line"
            # We build the elements conditional in the max level of savings at the steady state. The one that just crosses the 45 degree line
            lim_ind_a = size(a_grid)[1];
            a_sup = a_grid[lim_ind_a];
            lim_ind_k = size(k_grid)[1];
            new_a_grid = a_grid[1:lim_ind_a];
            new_k_grid = k_grid[1:lim_ind_k];
            dim_a = size(new_a_grid)[1];
            dim_k = size(new_k_grid)[1];
            new_A_prime = A_prime[1:lim_ind_a, 1:lim_ind_k, :, :];
            new_V = V[1:lim_ind_a, 1:lim_ind_k, :, :];
            new_Ind = Ind[1:lim_ind_a, 1:lim_ind_k, :, :];
            # Initial Condition
            # Let's establish that everybody starts at a middle capital level.
            inda0 = fill(findmin((abs.(k_grid[convert(Int,max(floor(dim_k/2),1))] .- a_grid)))[2], L, 1);
            A0 = new_a_grid[inda0];
            # We start in a random Aggregate State. And once that random aggegate state has been given we allocate job positions and adjust the number of workers to satisfy the unemployment rate at each one of the different aggregate states
            # If ϵ[n] = 1 it means that consumer n is working
            z0 = rand(Bernoulli(0.5), 1)==1 ? zg : zb;
            if z0 == zg
                ϵ0 = [rand(Bernoulli(1-μg)) == 1 ? ϵg : ϵb for p=1:L];
                ind = 0;
                while sum(ϵ0 .== ϵb)/L ≠ μg && ind < L;
                    ind += 1
                    if sum(ϵ0 .== ϵb)/L > μg
                        if ϵ0[ind] == ϵb
                            ϵ0[ind] = ϵg
                        end
                    elseif sum(ϵ0 .== ϵb)/L < μg
                        if ϵ0[ind] == ϵg
                            ϵ0[ind] = ϵb
                        end
                    end
                end
            elseif z0 == zb
                ϵ0 = [rand(Bernoulli(1-μb)) == 1 ? ϵg : ϵb for p=1:L];
                ind = 0;
                while sum(ϵ0 .== ϵb)/L ≠ μb && ind ≤ L;
                    ind += 1
                    if sum(ϵ0 .== ϵb)/L > μb
                        if ϵ0[ind] == ϵb
                            ϵ0[ind] = ϵg
                        end
                    elseif sum(ϵ0 .== ϵb)/L < μb
                        if ϵ0[ind] == ϵg
                            ϵ0[ind] = ϵb
                        end
                    end
                end
            end
            # With the initial level of capital we establish which is the initial aggregate level of capital
            indk0 =findmin(abs.(mean(A0) .- new_k_grid))[2]
            k0 = new_k_grid[indk0]
            z1 = z0;
            A1 = A0;
            ϵ1 = ϵ0;
            k1 = k0;
            μ1g = Inf;
            σ1g = Inf;
            sk1g = Inf;
            μ1b = Inf;
            σ1b = Inf;
            sk1b = Inf;
            supβ = Inf;
            supdist = Inf;
            R2g = 0.0;
            R2b = 0.0;
            σg = 1.0;
            σb = 1.0;
            Ω1 = Ω1;
        end
    end
    A1g = A1g
    A1b = A1b
    ϵ1g = ϵ1g
    ϵ1b = ϵ1b
    Yg = Yg
    Yb = Yb
    Xg = Xg
    Xb = Xb
    KSg = KSg;
    KSb = KSb;
    rg = rg;
    rb = rb;
    Ω = Ω1;
    R2g = R2g;
    R2b = R2b;
    σg = σg;
    σb = σb;
    elapsed = time() - start
    println("      Klevel(Krussel & Smith) solved in $elapsed seconds")
    return sol = [KSg, KSb, rg, rb, R2g, R2b, σg, σb, Ω, new_a_grid, new_k_grid, new_A_prime, new_V, a_grid, k_grid, Yg, Xg, Yb, Xb, A1g, A1b, ϵ1g, ϵ1b]
end
```




    KlevelKS (generic function with 1 method)




```julia
E = KlevelKS(u, du, θ, μ, z, ϵ, Π, Ω)
```

       Klevel(Krusell & Smith)...
          Kpolicy(Krussel & Smith)...
             Kpolicy solved in 2377 iter, with a sup metric of 9.910650078381877e-11 and in 1412.5699999332428 seconds
                Kpolicy has iterated 1 times  with a sup metric of 0.000627224649749143
                   and with (R2g, σg) = (0.9987044725378224,0.000244915489467494); (R2b, σb) = (0.9997032674736751,0.00015689185224710187)
                      dist. conv. in 7162 ite with a sup metric of 0.0.
                      Ω = [0.1094322475533505 0.078435577648264; 0.9747268108602258 0.9812777123694383].
                      (Kg, rg) = (75.82519536736596, 0.02219201817428643) and (Kb, rb) = (75.57636464807989, 0.02133890067878027).
(...)
             Kpolicy solved in 2303 iter, with a sup metric of 9.92486093309708e-11 and in 1379.417000055313 seconds
                Kpolicy has iterated 49 times  with a sup metric of 3.8734769215791184e-8
                   and with (R2g, σg) = (0.9994762800755673,0.00022954172054136541); (R2b, σb) = (0.9996781532562715,0.00020012953807067152)
                      dist. conv. in 1032 ite with a sup metric of 6.355146450499702e-8.
                      Ω = [0.07879186978192604 0.0675011662040322; 0.9783832227185817 0.9804834725782833].
                      (Kg, rg) = (35.746437791349294, 0.03590942829968761) and (Kb, rb) = (35.12465622082942, 0.03484555193525712).
          Klevel(Krussel & Smith) solved in 112143.52900004387 seconds


The results are:

- It took 49 iterations for the equilibrium to converge and it took around 31 hours to get this result.
- The equilibrium level of capital holdings is <img src="https://tex.s2cms.ru/svg/K_g%20%3D%2035.74" alt="K_g = 35.74" /> and <img src="https://tex.s2cms.ru/svg/K_b%3D35.12" alt="K_b=35.12" />. This values are consistent with the estimations reported in Den Haan (2010) that are between $37,67$ and $39,50$ (their model has an un unemployment insurance of <img src="https://tex.s2cms.ru/svg/15%5C%25" alt="15\%" />).
- The equilibrium interest rates are <img src="https://tex.s2cms.ru/svg/r_g%20%3D%203%2C59%5C%25" alt="r_g = 3,59\%" /> and <img src="https://tex.s2cms.ru/svg/r_b%3D%203%2C48%5C%25" alt="r_b= 3,48\%" />.
- For the good state we have <img src="https://tex.s2cms.ru/svg/%5Calpha_0%20%3D%200.07" alt="\alpha_0 = 0.07" />, <img src="https://tex.s2cms.ru/svg/%5Calpha_1%20%3D%200.9783" alt="\alpha_1 = 0.9783" />, <img src="https://tex.s2cms.ru/svg/R%5E2_g%20%3D%200.9999" alt="R^2_g = 0.9999" /> and <img src="https://tex.s2cms.ru/svg/%5Csigma_g%20%3D%200.0002295" alt="\sigma_g = 0.0002295" />.
- For the bas state we have <img src="https://tex.s2cms.ru/svg/%5Cbeta_0%20%3D%200.078" alt="\beta_0 = 0.078" />, <img src="https://tex.s2cms.ru/svg/%5Cbeta_1%20%3D%200.98048" alt="\beta_1 = 0.98048" />, <img src="https://tex.s2cms.ru/svg/R%5E2_b%20%3D%200.9999" alt="R^2_b = 0.9999" /> and <img src="https://tex.s2cms.ru/svg/%5Csigma_b%20%3D%200.0002001" alt="\sigma_b = 0.0002001" />.
- With unemployment insurance Maiar et al (2010) get  <img src="https://tex.s2cms.ru/svg/%5Calpha_0%20%3D%200.123815" alt="\alpha_0 = 0.123815" />, <img src="https://tex.s2cms.ru/svg/%5Calpha_1%20%3D%200.965565" alt="\alpha_1 = 0.965565" />, <img src="https://tex.s2cms.ru/svg/%5Cbeta_0%20%3D%200.1378" alt="\beta_0 = 0.1378" />, and <img src="https://tex.s2cms.ru/svg/%5Cbeta_1%20%3D%200.963228" alt="\beta_1 = 0.963228" />.



```julia
using KernelDensity, AverageShiftedHistograms
```

### **Observed and predicted level of capital**


```julia
plot(1:size(E[16])[1], exp.(E[16]), label="Observed", title = "Observed and Predicted level of per capita Aggregate K in zg")
plot!(1:size(E[16])[1], exp.(E[17]), label="Predicted")
```




![svg](/Krusell_and_Smith(1998)_files/output_55_0.svg)




```julia
plot(1:size(E[18])[1], exp.(E[18]), label="Observed", title = "Observed and Predicted level of per capita Aggregate K in zb")
plot!(1:size(E[18])[1], exp.(E[19]), label="Predicted")
```




![svg](/Krusell_and_Smith(1998)_files/output_56_0.svg)



### **PDF asset distribution conditional on aggregate shock**


```julia
plot(ash(vec(E[20]); m =20), legend=:topleft, label="Boom", title = "PDF asset distribution conditional on Aggregate shock"; hist = false)
plot!(ash(vec(E[21]); m =20), label="Bust"; hist = false)
```




![svg](/Krusell_and_Smith(1998)_files/output_58_0.svg)




```julia
plot(ash(vec(E[20][E[22] .== ϵg]); m=20), legend=:topleft, label = "Employed Boom", title = "PDF asset holdings for employed in boom and bust" ; hist = false)
plot!(ash(vec(E[21][E[23] .== ϵg]); m=20),  label = "Employed Bust" ; hist = false)
```




![svg](/Krusell_and_Smith(1998)_files/output_59_0.svg)




```julia
plot(ash(vec(E[20][E[22] .== ϵb]); m=30), legend=:topright, label = "Unemployed Boom", title = "PDF asset holdings for unemployed in boom and bust" ; hist = false)
plot!(ash(vec(E[21][E[23] .== ϵb]); m=30),  label = "Unemployed Bust" ; hist = false)
```




![svg](/Krusell_and_Smith(1998)_files/output_60_0.svg)




```julia
grid_elements = 150;
plot(E[10][1:grid_elements],[count((E[20] .<= E[10][s])) for s in 1:grid_elements] ./ L, legend=:bottomright, label = "Boom", title = "CDF asset holdings at low levels of asset")
plot!(E[10][1:grid_elements],[count((E[21] .<= E[10][s])) for s in 1:grid_elements] ./ L, label = "Bust")
```




![svg](/Krusell_and_Smith(1998)_files/output_61_0.svg)




```julia
grid_elements = 250;
plot(E[10][1:grid_elements],[count((E[20] .<= E[10][s])) for s in 1:grid_elements] ./ L, legend=:bottomright, label = "Boom", title = "CDF asset holdings at low levels of asset")
plot!(E[10][1:grid_elements],[count((E[21] .<= E[10][s])) for s in 1:grid_elements] ./ L, label = "Bust")
```




![svg](/Krusell_and_Smith(1998)_files/output_62_0.svg)
